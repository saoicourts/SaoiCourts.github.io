<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Bundle Networks</title>

		<link rel="stylesheet" href="../dist/reset.css">
		<link rel="stylesheet" href="../dist/reveal.css">
		<link rel="stylesheet" href="../dist/theme/beige.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="../plugin/highlight/monokai.css" id="highlight-theme">

		<style>
			.blue-highlight { color: #1b91ff}
			.red-highlight {color: crimson}
			.green-highlight {color:rgb(127, 167, 60)}
			.orange-highlight {color:darkorange}
		</style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
					<textarea data-template>
						## Bundle Networks
						#### Fiber Bundles, Local Trivializations, and a Generative Approach to Exploring Many-to-one Maps
						<br>

						<span class="orange-highlight">Nico Courts</span>

						UW Seattle & Pacific Northwest National Laboratory

						nico@nicocourts.com
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						Joint work with
						
						<span class="blue-highlight">Henry Kvinge</span>
						
						Pacific Northwest National Laboratory
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						Slides for this presentation can be found at
						#### https://nicocourts.com/talks/bundlenets/
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Background and overview
						Work completed during my second summer at PNNL.

						Resulting work was written up into [a manuscript](https://arxiv.org/abs/2110.06983) that has been submitted to ICLR 2022 (with generally favorable reviews so far).

						Will result in a <span class="green-highlight">public GitHub repo</span> with data and code for reproducibility once it is cleared by the lab for release.
					</textarea>
				</section>



				<section data-markdown>
					<textarea data-template>
						### Outline
						- Bundle Networks
							- <span class='green-highlight'>Problem formulation &amp; approach</span>
							- <span class='orange-highlight'>Model selection &amp; tuning</span>
							- <span class='red-highlight'>Performance &amp; analysis</span>
					</textarea>
				</section>
				<section>
					<h2>Bundle Networks</h2>
					<h3><span class='green-highlight'>Part I: Problem formulation and approach</span></h3>
				</section>
				
				<section data-markdown data-auto-animate>
					<textarea data-template>
						### Motivation: Materials science
						During this portion of my internship, I served alongside data scientists who were helping materials scientists analyze their fabrication data. 
					</textarea>
				</section>
				<section data-markdown data-auto-animate>
					<textarea data-template>
						### Motivation: Materials science
						There are many human-designed parameters that can be changed to affect the end product, but often researchers are only interested 
						in one (or very few) output parameters.

						![many-to-one process](images/many-to-one.png)<!--.element: style="width:40%"-->
					</textarea>
				</section>
				<section data-markdown data-auto-animate>
					<textarea data-template>
						### A question
						An early observation we made is that the manufacturing process naturally formed a <span class="red-highlight">many-to-one map.</span>

						One question one may ask is <span class="green-highlight">"In what ways can I change my configuration that keeps the end product constant?"</span>
					</textarea>
				</section>
				<section data-markdown data-auto-animate>
					<textarea data-template>
						### A question
						One may be interested in answering this for several reasons:
						- Some manufacturing configurations may be <span class="green-highlight">cheaper</span>
							- e.g. using a less expensive billet materials
						- Some parameter choices may result in a <span class="blue-highlight">more stable process</span>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### A mathematical perspective
						Whenever we, as mathematicians, encounter many-to-one maps, we begin to wonder what kinds of structure such a map may have. Common examples of 
						surjective maps in topology and geometry include
						- <span class="red-highlight">(Topological) quotients</span>
						- <span class="blue-highlight">Fiber Bundles</span>
						- <span class="orange-highlight">Covering maps</span> 
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Idea: Quotient maps

						A <span class="red-highlight">topological quotient</span> is a simply a continuous (or suitably smooth) surjective map. This is a very general
						notion, so there is very little we can assume about quotient maps in generality.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Idea: Fiber bundles
						![bundles](images/bundle.png)<!--.element: style="width:60%"-->

						A <span class="blue-highlight">fiber bundle</span> is a base space $X$, a total space $E$, and a surjection $\pi:E\to X$ satisfying <span class="red-highlight">local triviality.</span>
						In essence, this means that $E$ is a space parameterized by $X$ that is <span class="green-highlight">basically the same everywhere.</span>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Idea: Covering maps

						A <span class="orange-highlight">covering map</span> is a surjective map $p:E\to X$ where each point $x$ has a neighborhood $U$ with $p^{-1}(U)$ homeomorphic to 
						a disjoint union of copies of $U$.

						![covering map](images/covering-space.png)

						<span style="font-size: 15px;">https://en.wikipedia.org/wiki/Covering_space</span>
					</textarea>
				</section>
				<section data-markdown data-auto-animate>
					<textarea data-template>
						### Why fiber bundles?
						<span class="red-highlight">Quotient maps</span> seemed too general a framework for our case. 

						<span class="orange-highlight">Covering maps</span> seemed too specific (they are fiber bundles with discrete fibers).
					</textarea>
				</section>
				<section data-markdown data-auto-animate>
					<textarea data-template>
						### Why fiber bundles?
						We worked under the hypothesis that the modes of variance that were collapsed 
						over each point were comparable.
						
						<span class="blue-highlight">Fiber bundles</span> were the right blend of generality and structure for this assumption.

					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Distilling the problem
						Under the assumption that the true data lies on a fiber bundle, we can rephrase the problem in the following way:

						Create a model that performs density estimation on the <span class="orange-highlight">fiber over a point</span>, that is, $\pi^{-1}(y)$ for any $y$ in the base space. 
						
						In doing so, construct a <span class="red-highlight">fiberwise-accurate reconstruction</span> of the true bundle underlying the data.
					</textarea>
				</section>



				<section>
					<h2>Bundle Networks</h2>
					<h3><span class='orange-highlight'>Part II: Model selection &amp; tuning</span></h3>
				</section>
				<section data-markdown>
					<textarea data-template>
						#### Capabilities required
						- Sample from the distribution of points on the fiber over a point
						- Use a single model (instead of an ensemble)

						#### Expected difficulties <!--.element: style="margin-top:30px"-->
						- Data will be sparse (finite) in general
						- Global data distribution may be too complicated for traditional architectures to model
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Overview
						We use <span class="orange-highlight">fiber bundles</span> to address the fact we expect the local data distribution is 
						simpler than the global and that local structure will be somewhat homogeneous.

						We use <span class="green-highlight">normalizing flows</span> to perform density estimation in trivial neighborhoods.

						We use <span class="red-highlight">invertible neural nets</span> to implement our model, allowing simultaneous forward and backward
						training, as well as lossless connection between $\pi^{-1}(U)$ and $U\times F$.
					</textarea>
				</section>
				<section data-auto-animate>
					<section>
						<h3>Density estimation using normalizing flows</h3>
						<p>
							In (<a href="http://proceedings.mlr.press/v37/rezende15.html">Rezende and Mohammed, 2015</a>), 
							the authors suggest an approach to density estimation (i.e. posterior approximation) 
							using the framework of normalizing flows. 
						</p><p>
							Here, given some choice of prior $p$ on space $X$, 
							we learn a function $\Phi:Y\to X$ which gives distribution $q$ on $Y$ <span class="green-highlight">parameterized by $p$</span>:
						</p>
						$$q(y')=p(\Phi(y'))|D\Phi(y')|$$
					</section>
					<section>
						<h4>References</h4>
						<span style="font-size:25px"><strong>Danilo Rezende, Shakir Mohamed</strong> "Variational Inference with Normalizing Flows" <em>Proceedings of the 32nd International Conference on Machine Learning</em>, PMLR 37:1530-1538, 2015.
						(<a href="http://proceedings.mlr.press/v37/rezende15.html">link</a>)</span>
					</section>
				</section>
				<section data-auto-animate>
					<section>
						<h3>Invertible neural nets</h3>
						<p>
							INNs are a class of NN blocks that are, by construction, invertible. They were first used by <a href="https://arxiv.org/abs/1410.8516">(Dinh et al., 2015)</a> to perform a 
							kind of independent component analysis (ICA) and then in <a href="https://arxiv.org/abs/2001.04872">(Dinh et al., 2017)</a> to perform density estimation.
						</p>
					</section>
					<section>
						<h4>References</h4>
						<span style="font-size:25px">
							<strong>Laurent Dinh, David Krueger, and Yoshua Bengio</strong> 
							"NICE: Non-linear Independent Components Estimation" 
							<em>arXiv preprint arXiv:1410.8516</em>, 2015
							(<a href="https://arxiv.org/abs/1410.8516">link</a>)
						</span><br /><br />

						<span style="font-size:25px">
							<strong>Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio</strong>
							"Density estimation using real NVP"
							<em>International Conference on Learning Representations</em>, 2017
							(<a href="https://arxiv.org/abs/2001.04872">link</a>)
						</span>
					</section>
				</section>
				<section>
					<section>
						<h3>Invertible neural networks</h3>
						<div style="display:flex; justify-content: space-around; align-items: center;">
							<div style="width:60%">
								The work in <a href="https://arxiv.org/abs/2001.04872">(Sorrenson et al., 2019)</a> served as an inspiration for the power of this approach 
								in their <span class="blue-highlight">automated feature discovery and isolation</span> applied to MNIST.
							</div>
							<div style="width:30%">
								<img src="images/samples.png">
							</div>
						</div>
					</section>
					<section>
						<h4>References</h4>
						<span style="font-size:25px">
							<strong>Peter Sorrenson, Carsten Rother, and Ullrich Köthe</strong>
							"Disentanglement by Nonlinear ICA with General Incompressible-flow Networks (GIN)" 
							<em>International Conference on Learning Representations</em>, 2019
							(<a href="https://arxiv.org/abs/2001.04872">link</a>)
						</span>
					</section>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Features extracted
						<div style="display:flex; justify-content: space-around; align-items: center;">
							<div style="width:30%">
								<img src="images/var1.png">
							</div>
							<div style="width:30%">
								<img src="images/var2.png">
							</div>
							<div style="width:30%">
								<img src="images/var3.png">
							</div>
						</div>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Nonlinear ICA
						![nonlinear ica](images/nonlinear-ica.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Using neighborhoods
						**Input:** Data in the total space $\mathcal{D}_\text{bundle}\subseteq X$ and base space $\mathcal{D}_\text{base}\subseteq Y$.
						
						Compute <span class="blue-highlight">neighborhoods $\\{U_i\\}_{i\in\mathcal I}$</span> in $\mathcal{D}_\text{base}$, 
						each with a <span class="red-highlight">representative point $r_i\in U_i$</span>.
						
						To run the model, <span class="red-highlight">condition on nearest $r\in \mathcal{R}=\\{r_i\\}_{i\in\mathcal I}$</span>.
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Model architecture
						![model](images/model.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Notation
						In the following we use
						- $\Phi:X\times \mathcal R\to Y\times \mathcal D$ is our model
							- $\Phi_i=\Phi(-,r_i):X\to Y\times\mathcal D$

						- $x$ is a point in $\mathcal{D}_\text{bundle}$ lying over $y\in\mathcal{D}_\text{base}$.
						- $r_i$ is $\operatorname{argmin}_\{r_j\in\mathcal R\}\\|y-r_j\\|$
						- $p_Z$ is projection onto the $Z$ component
						- Sample $z_k\sim\mathcal D$ and let $\widetilde X=\\{\Phi_i^{-1}(y, z_k)\\}$
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Loss terms
						- Forward loss
							- **Mean squared error**: $\\|y-p_Y(\Phi(x))\\|^2$
						- Backward loss 
							- **KL-fwd**: $D_\text{KL}(\pi^\{-1\}(y)||\widetilde X)$
							- **KL-bwd**: $D_\text{KL}(\widetilde X||\pi^\{-1\}(y))$
							- **Mean squared minimum distance (MSMD)**:
							$$\frac{1}{|\widetilde X|}\sum_{\tilde x\in\widetilde X}\min_{x\in\pi^{-1}(y)}\\|x-\tilde x\\|$$
					</textarea>
				</section>



				<section>
					<h2>Bundle Networks</h2>
					<h3><span class='red-highlight'>Part III: Performance &amp; analysis</span></h3>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Models tested
						- Our model, <span class="blue-highlight">BundleNet</span>
						- <span class="green-highlight">WGAN</span>&mdash;Wasserstein GAN 
						- <span class="red-highlight">CGAN</span>&mdash;Conditional GAN 
							- Conditioned on individual base points 
							- Batches drawn from global distribution
						- <span class="orange-highlight">CGAN-local</span>&mdash;A CGAN that
							- is conditioned on finitely many neighborhood representatives
							- is trained with batches drawn from a single neighborhood at a time
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Datasets&mdash;Synthetic
						- <span class="blue-highlight">Torus</span>, points drawn from a torus in $\mathbb R^3$ lying over a circle.
						- <span class="green-highlight">Möbius Band</span>, points drawn from a Möbius band in $\mathbb R^3$ lying over a circle.
					</textarea>
				</section>
				<section data-markdown data-auto-animate>
					<textarea data-template>
						### Datasets&mdash;Real-world
						<span class="orange-highlight">Wine Quality</span>, a real dataset consisting of 11 measured quantities (below), with each being assigned a (color, quality) pair.
						<div style="column-count:2">
							<div><ul>
								<li>fixed acidity</li>
								<li>volatile acidity</li>
								<li>citric acid</li>
								<li>residual sugar</li>
								<li>chlorides</li>
								<li>free sulfur dioxide</li>
							</ul></div>
							<div><ul>
								<li>total sulfur dioxide</li>
								<li>density</li>
								<li>pH</li>
								<li>sulphates</li>
								<li>alcohol</li>
							</ul></div>
						</div>
					</textarea>
				</section>
				<section data-markdown data-auto-animate>
					<textarea data-template>
						### Datasets&mdash;Real-world
						<span class="red-highlight">Airfoil Noise</span>, a real dataset consisting of five parameters and their measured effect on sound pressure.
						- frequency (Hz)
						- angle of attack (deg)
						- chord length (m)
						- free-stream velocity (m/s)
						- suction side displacement thickness (m)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Results
						![bundlenet results](images/bn-results.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Reconstructions
						<div style="display:flex; justify-content: center;"><div id='bn-torus' style="width:50%; overflow:hidden"></div><div id='cgan-torus' style="width:50%; overflow:hidden"></div></div>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Reconstructions
						<div style="display:flex; justify-content: center;"><div id='bn-moeb' style="width:50%; overflow:hidden"></div><div id='cgan-moeb' style="width:50%; overflow:hidden"></div></div>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Observation: Circular vs Gaussian priors
						![priors](images/prior_pictures.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Observation: Circular priors may work better?
						![priors](images/priors.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Observation: Fibers need not be uniform
						<div style="display:flex; justify-content: center;"><div id='bn-sliced' style="width:50%"></div></div>
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						### Future directions
						We found that there were many directions still worth pursuing related to this work:
						- High-dimensional data
						- Convolutional architectures
						- Further examination of topology of priors
						- When is the fiber bundle hypothesis appropriate?
							- Is it sometimes harmful?
					</textarea>
				</section>


				<section>
					<h2>Thank you!</h2>
				</section>
			</div>
		</div>

		<script src="../dist/reveal.js"></script>
		<script src="../plugin/math/math.js"></script>
		<script src="../plugin/markdown/markdown.js"></script>
		<script src="../plugin/highlight/highlight.js"></script>
		<script src="../plugin/zoom/zoom.js"></script>
		<script src="https://d3js.org/d3.v7.min.js"></script>
		<script src="https://cdn.plot.ly/plotly-2.6.3.min.js"></script>


		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				
				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealMath, RevealZoom ]
			});

			// helper function for plotly
			function unpack(rows, key) {
				return rows.map(function(row) { return row[key]; });
			}

			var use_width = screen.width/5

			// Load data and populate graph
			fetch('data/BN_torus.json')
				.then(response => response.json())
				.then(function(data){
					var unpacked = [{
						x: unpack(data, 'bundle_x'),
						y: unpack(data, 'bundle_y'),
						z: unpack(data, 'bundle_z'),
						mode: 'markers',
						type: 'scatter3d',
						
						marker: {
						color: unpack(data, 'angle'),
						size: 2,
						colorscale: 'Jet',
						}
					}];

					layout = {
						title: "BundleNet Torus Reconstruction",
						width: use_width,
						scene:{
							
							aspectmode: "manual",
							aspectratio: {
							x: 1, y: 1, z: 1,
							},
							xaxis: {
							nticks: 9,
							range: [-10, 10],
							},
							yaxis: {
							nticks: 7,
							range: [-10, 10],
							},
							zaxis: {
							nticks: 10,
							range: [-10, 10],
							}
						}
					};

					// plot!
					Plotly.newPlot('bn-torus', unpacked, layout);
				})
				// CGAN torus
				fetch('data/CGAN_triv_torus.json')
				.then(response => response.json())
				.then(function(data){
					var unpacked = [{
						x: unpack(data, 'bundle_x'),
						y: unpack(data, 'bundle_y'),
						z: unpack(data, 'bundle_z'),
						mode: 'markers',
						type: 'scatter3d',
						
						marker: {
						color: unpack(data, 'angle'),
						size: 2,
						colorscale: 'Jet',
						}
					}];

					layout = {
						title: "CGAN-local Torus Reconstruction",
						width: use_width,
						scene:{
							
							aspectmode: "manual",
							aspectratio: {
							x: 1, y: 1, z: 1,
							},
							xaxis: {
							nticks: 9,
							range: [-10, 10],
							},
							yaxis: {
							nticks: 7,
							range: [-10, 10],
							},
							zaxis: {
							nticks: 10,
							range: [-10, 10],
							}
						}
					};

					// plot!
					Plotly.newPlot('cgan-torus', unpacked, layout);
				})
			// moeb
			fetch('data/BN_moebius.json')
				.then(response => response.json())
				.then(function(data){
					var unpacked = [{
						x: unpack(data, 'bundle_x'),
						y: unpack(data, 'bundle_y'),
						z: unpack(data, 'bundle_z'),
						mode: 'markers',
						type: 'scatter3d',
						
						marker: {
						color: unpack(data, 'angle'),
						size: 2,
						colorscale: 'Jet',
						}
					}];

					layout = {
						title: "BundleNet Moebius Band Reconstruction",
						width: use_width,
						scene:{
							
							aspectmode: "manual",
							aspectratio: {
							x: 1, y: 1, z: 1,
							},
							xaxis: {
							nticks: 9,
							range: [-10, 10],
							},
							yaxis: {
							nticks: 7,
							range: [-10, 10],
							},
							zaxis: {
							nticks: 10,
							range: [-10, 10],
							}
						}
					};

					// plot!
					Plotly.newPlot('bn-moeb', unpacked, layout);
				})
				// CGAN moeb
				fetch('data/CGAN_triv_moebius.json')
				.then(response => response.json())
				.then(function(data){
					var unpacked = [{
						x: unpack(data, 'bundle_x'),
						y: unpack(data, 'bundle_y'),
						z: unpack(data, 'bundle_z'),
						mode: 'markers',
						type: 'scatter3d',
						
						marker: {
						color: unpack(data, 'angle'),
						size: 2,
						colorscale: 'Jet',
						}
					}];

					layout = {
						title: "CGAN-local Moebius Band Reconstruction",
						width: use_width,
						scene:{
							aspectmode: "manual",
							aspectratio: {
							x: 1, y: 1, z: 1,
							},
							xaxis: {
							nticks: 9,
							range: [-10, 10],
							},
							yaxis: {
							nticks: 7,
							range: [-10, 10],
							},
							zaxis: {
							nticks: 10,
							range: [-10, 10],
							}
						}
					};

					// plot!
					Plotly.newPlot('cgan-moeb', unpacked, layout);
				})
			// sliced
			fetch('data/BN_sliced.json')
				.then(response => response.json())
				.then(function(data){
					var unpacked = [{
						x: unpack(data, 'bundle_x'),
						y: unpack(data, 'bundle_y'),
						z: unpack(data, 'bundle_z'),
						mode: 'markers',
						type: 'scatter3d',
						
						marker: {
						color: unpack(data, 'angle'),
						size: 2,
						colorscale: 'Jet',
						}
					}];

					layout = {
						title: "BundleNet Sliced Torus Reconstruction",
						width: use_width,
						scene:{
							aspectmode: "manual",
							aspectratio: {
							x: 1, y: 1, z: 1,
							},
							xaxis: {
							nticks: 9,
							range: [-10, 10],
							},
							yaxis: {
							nticks: 7,
							range: [-10, 10],
							},
							zaxis: {
							nticks: 10,
							range: [-10, 10],
							}
						}
					};

					// plot!
					Plotly.newPlot('bn-sliced', unpacked, layout);
				})
		</script>
	</body>
</html>
